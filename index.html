<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<title>RabbitMQ PerfTest</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
/*! Stylesheet for CodeRay to loosely match GitHub themes | MIT License */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid;opacity:.35;padding:0 .5em 0 0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff!important;background:navy!important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:navy}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:teal}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:teal}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:teal}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword{color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:teal}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.js"></script>
</head>
<body class="article toc2 toc-left">
<div id="header">
<h1>RabbitMQ PerfTest</h1>
<div class="details">
<span id="revnumber">version 2.24.0-SNAPSHOT</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#installation">Installation</a>
<ul class="sectlevel2">
<li><a href="#from-binary">From Binary</a></li>
<li><a href="#from-docker-image">From Docker Image</a></li>
</ul>
</li>
<li><a href="#basic-usage">Basic Usage</a></li>
<li><a href="#how-it-works">How It Works</a></li>
<li><a href="#stopping-perftest">Stopping PerfTest</a></li>
<li><a href="#customising-queues">Customising queues</a>
<ul class="sectlevel2">
<li><a href="#quorum-queue-support">Quorum Queue Support</a></li>
<li><a href="#stream-support">Stream Support</a></li>
</ul>
</li>
<li><a href="#customising-messages">Customising messages</a>
<ul class="sectlevel2">
<li><a href="#message-properties">Message Properties</a></li>
<li><a href="#message-payload-from-files">Message Payload from Files</a></li>
<li><a href="#random-json-payload">Random JSON Payload</a></li>
</ul>
</li>
<li><a href="#limiting-and-varying-publishing-rate">Limiting and varying publishing rate</a></li>
<li><a href="#setting-and-varying-the-message-size">Setting and varying the message size</a></li>
<li><a href="#setting-and-varying-consumer-latency">Setting and varying consumer latency</a></li>
<li><a href="#working-with-many-queues">Working With Many Queues</a></li>
<li><a href="#simulating-high-loads">Simulating High Loads</a></li>
<li><a href="#workloads-with-a-large-number-of-clients">Workloads With a Large Number of Clients</a></li>
<li><a href="#running-producers-and-consumers-on-different-machines">Running Producers and Consumers on Different Machines</a></li>
<li><a href="#asynchronous-consumers-vs-synchronous-consumers">Asynchronous Consumers vs Synchronous Consumers</a></li>
<li><a href="#consuming-from-streams">Consuming From Streams</a></li>
<li><a href="#instance-synchronization">Synchronizing Several Instances</a></li>
<li><a href="#tls-support">TLS Support</a></li>
<li><a href="#oauth2-authenticationauthorization">OAuth2 authentication/authorization</a></li>
<li><a href="#using-environment-variables-as-options">Using Environment Variables as Options</a></li>
<li><a href="#console-output-format">Console Output Format</a></li>
<li><a href="#monitoring">Monitoring</a>
<ul class="sectlevel2">
<li><a href="#supported-metrics">Supported Metrics</a></li>
<li><a href="#tags">Tags</a></li>
<li><a href="#supported-monitoring-systems">Supported Monitoring Systems</a></li>
<li><a href="#expected-and-exposed-metrics">Expected and Exposed Metrics</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>PerfTest is a throughput testing tool for <a href="https://www.rabbitmq.com/">RabbitMQ</a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="introduction"><a class="anchor" href="#introduction"></a>Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://www.rabbitmq.com/">RabbitMQ</a> has a throughput testing tool,
PerfTest, that is based on
the Java client and can be configured to simulate basic
workloads and <a href="#workloads-with-a-large-number-of-clients">more advanced workloads</a> as well.
PerfTest has extra tools that produce HTML graphs of the output.</p>
</div>
<div class="paragraph">
<p>A RabbitMQ cluster can be limited by a number of factors,
from infrastructure-level constraints (e.g. network bandwidth) to
RabbitMQ configuration and topology to applications that publish
and consume. PerfTest can demonstrate baseline performance of a
node or a cluster of nodes.</p>
</div>
<div class="paragraph">
<p>PerfTest uses the <a href="https://www.rabbitmq.com/tutorials/amqp-concepts.html">AMQP 0.9.1 protocol</a> to communicate with a RabbitMQ cluster.
Use <a href="https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#the-performance-tool">Stream PerfTest</a> if you want to test <a href="https://rabbitmq.com/streams.html">RabbitMQ Streams</a> with the <a href="https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbitmq_stream/docs/PROTOCOL.adoc">stream protocol</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="installation"><a class="anchor" href="#installation"></a>Installation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>PerfTest requires at least Java 8, but <a href="#instance-synchronization">some features</a> require Java 11.
The latest LTS Java version is recommended.</p>
</div>
<div class="sect2">
<h3 id="from-binary"><a class="anchor" href="#from-binary"></a>From Binary</h3>
<div class="paragraph">
<p>PerfTest is distributed as an uber JAR from <a href="https://github.com/rabbitmq/rabbitmq-perf-test/releases">GitHub releases</a>.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
The <code>tar.gz</code> and <code>zip</code> archives are deprecated and will be removed in PerfTest 3.0.
Use the uber JAR file instead.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>It is also available on <a href="https://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.rabbitmq%22%20AND%20a%3A%22perf-test%22">Maven Central</a> if one needs to use it as library.</p>
</div>
<div class="paragraph">
<p>Milestone releases or release candidates are available from <a href="https://github.com/rabbitmq/rabbitmq-perf-test/releases">GitHub releases</a>.</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/rabbitmq/rabbitmq-java-tools-binaries-dev/releases?q=rabbitmq-perf-test">Snapshots</a> are also available.
The <a href="https://github.com/rabbitmq/rabbitmq-java-tools-binaries-dev/releases/download/v-rabbitmq-perf-test-latest/perf-test-latest.jar">latest snapshot</a> is available at a stable URL (useful for automation).</p>
</div>
<div class="paragraph">
<p>To verify a PerfTest installation, use:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --help</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="from-docker-image"><a class="anchor" href="#from-docker-image"></a>From Docker Image</h3>
<div class="paragraph">
<p>PerfTest has a <a href="https://hub.docker.com/r/pivotalrabbitmq/perf-test/">Docker image</a> as well.
To use it:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>docker run -it --rm pivotalrabbitmq/perf-test:latest --help</pre>
</div>
</div>
<div class="paragraph">
<p>Note that the Docker container needs to be able to connect to the host where
the RabbitMQ broker runs.  Find out more at
<a href="https://docs.docker.com/network/">Docker network documentation</a>.  Once the
Docker container where PerfTest runs can connect to the RabbitMQ broker,
PerfTest can be run with the regular options, e.g.:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>docker run -it --rm pivotalrabbitmq/perf-test:latest -x 1 -y 2 -u "throughput-test-1" -a --id "test 1"</pre>
</div>
</div>
<div class="paragraph">
<p>To run the RabbitMQ broker within Docker, and run PerfTest against it, run the
following commands:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>docker network create perf-test
docker run -it --rm --network perf-test --name rabbitmq -p 15672:15672 rabbitmq:4.0-management
docker run -it --rm --network perf-test pivotalrabbitmq/perf-test:latest --uri amqp://rabbitmq</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="basic-usage"><a class="anchor" href="#basic-usage"></a>Basic Usage</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The most basic way of running PerfTest only specifies a URI to
connect to, a number of publishers to use (say, 1) and a
number of consumers to use (say, 2). Note that RabbitMQ Java
client can achieve high rates for publishing (up to 80 to 90K
messages per second per connection), given enough bandwidth and when some safety
measures (publisher confirms) are disabled, so overprovisioning
publishers is rarely necessary (unless that&#8217;s a specific objective of the test).</p>
</div>
<div class="paragraph">
<p>The following command runs PerfTest with a single publisher
without publisher confirms, two consumers (each receiving a
copy of every message) that use automatic acknowledgement mode
and a single queue named “throughput-test-x1-y2”. Publishers
will publish as quickly as possible, without any rate
limiting. Results will be prefixed with “test1” for easier
identification and comparison:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-1" -a --id "test 1"</pre>
</div>
</div>
<div class="paragraph">
<p>This modification will use 2 publishers and 4 consumers,
typically yielding higher throughput given enough CPU cores
on the machine and RabbitMQ nodes:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 2 -y 4 -u "throughput-test-2" -a --id "test 2"</pre>
</div>
</div>
<div class="paragraph">
<p>This modification switches consumers to manual acknowledgements:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-3" --id "test 3"</pre>
</div>
</div>
<div class="paragraph">
<p>This modification changes message size from default (12 bytes) to 4 kB:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-4" --id "test 4" -s 4000</pre>
</div>
</div>
<div class="paragraph">
<p>PerfTest can use durable queues and persistent messages:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-5" --id "test-5" -f persistent</pre>
</div>
</div>
<div class="paragraph">
<p>When PerfTest is running, it is important to monitor various
publisher and consumer metrics provided by the <a href="https://www.rabbitmq.com/management.html">management UI</a>.
For example, it is possible to see how much network
bandwidth a publisher has been using recently on the
connection page.</p>
</div>
<div class="paragraph">
<p>Queue page demonstrates message rates, consumer count,
acknowledgement mode used by the consumers, consumer
utilisation and message location break down (disk, RAM,
paged out transient messages, etc). When durable queues and
persistent messages are used, node I/O and message
store/queue index operation metrics become particularly
important to monitor.</p>
</div>
<div class="paragraph">
<p>Consumers can ack multiple messages at once, for example, 100 in this configuration:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-6" --id "test-6" \
  -f persistent --multi-ack-every 100</pre>
</div>
</div>
<div class="paragraph">
<p><a href="https://www.rabbitmq.com/confirms.html">Consumer prefetch (QoS)</a> can be configured as well
(in this example to 500):</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-7" --id "test-7" \
  -f persistent --multi-ack-every 200 -q 500</pre>
</div>
</div>
<div class="paragraph">
<p>Publisher confirms can be used with a maximum of N outstanding publishes:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-8" --id "test-8" \
  -f persistent -q 500 -c 500</pre>
</div>
</div>
<div class="paragraph">
<p>PerfTest can publish only a certain number of messages instead of running until shut down:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-10" --id "test-10" \
  -f persistent -q 500 -pmessages 100000</pre>
</div>
</div>
<div class="paragraph">
<p>Publisher rate can be limited:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-11" --id "test-11" \
  -f persistent -q 500 --rate 5000</pre>
</div>
</div>
<div class="paragraph">
<p>Consumer rate can be limited as well to simulate slower consumers or create a backlog:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-12" --id "test-12" \
  -f persistent --rate 5000 --consumer-rate 2000</pre>
</div>
</div>
<div class="paragraph">
<p>Note that the consumer rate limit is applied per consumer, so in the
configuration above the limit is actually 2 * 2000 = 4000
deliveries/second.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>PerfTest automatically converts low publishing rates (between 1 and 10 messages / second) to <a href="#workloads-with-a-large-number-of-clients">publishing intervals</a>.
This makes the simulation more accurate when simulating many slow publishers.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>PerfTest can be configured to run for a limited amount of time in seconds with the
<code>-z</code> option:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 1 -y 2 -u "throughput-test-13" --id "test-13" \
  -f persistent -z 30</pre>
</div>
</div>
<div class="paragraph">
<p>Running PerfTest without consumers and with a limited number
of messages can be used to pre-populate a queue, e.g. with
1M messages 1 kB in size each::</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -y0 -p -u "throughput-test-14" \
  -s 1000 -C 1000000 --id "test-14" -f persistent</pre>
</div>
</div>
<div class="paragraph">
<p>Use the <code>-D</code> option to limit the number of consumed messages. Note
the <code>-z</code> (time limit), <code>-C</code> (number of
published messages), and <code>-D</code> (number of consumed messages)
options can be used together but their combination can lead to funny results.
<code>-r 1 -x 1 -C 10 -y 1 -D 20</code> would for example stop the producer
once 10 messages have been published, letting the consumer wait forever
the remaining 10 messages (as the publisher is stopped).</p>
</div>
<div class="paragraph">
<p>To consume from a pre-declared and pre-populated queue without starting any publishers,
use</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x0 -y10 -p -u "throughput-test-14" --id "test-15"</pre>
</div>
</div>
<div class="paragraph">
<p>PerfTest is useful for establishing baseline cluster throughput with
various configurations but does not simulate many other aspects of
real world applications. It is also biased towards very simplistic
workloads that use a single queue, which provides <a href="https://www.rabbitmq.com/queues.html">limited CPU utilisation</a>
on RabbitMQ nodes and is not recommended for most cases.</p>
</div>
<div class="paragraph">
<p>Multiple PerfTest instances running simultaneously can be used to
simulate more realistic workloads.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="how-it-works"><a class="anchor" href="#how-it-works"></a>How It Works</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If a queue name is defined (<code>-u "queue-name"</code>),
PerfTest will create a queue with this name and all
consumers will consume from this queue. The queue will be
bound to the direct exchange with its name as the routing
key. The routing key will be used by producers to send
messages.  This will cause messages from all producers to be
sent to this single queue and all consumers to receive
messages from this single queue.</p>
</div>
<div class="paragraph">
<p>If the queue name is not defined, PerfTest will create a
random UUID routing key with which producers will publish
messages.  Each consumer will create its own anonymous queue
and bind it to the direct exchange with this routing key.
This will cause each message from all producers to be
replicated to multiple queues (number of queues equals
number of consumers), while each consumer will be receiving
messages from only one queue.</p>
</div>
<div class="paragraph">
<p>Note it is possible to <a href="#customising-queues">customise</a>
the queue and to work against <a href="#working-with-many-queues">several queues</a> as well.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="stopping-perftest"><a class="anchor" href="#stopping-perftest"></a>Stopping PerfTest</h2>
<div class="sectionbody">
<div class="paragraph">
<p>There are 2 reasons for a PerfTest run to stop:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>one of the limits has been reached (time limit, producer or consumer message count)</p>
</li>
<li>
<p>the process is stopped by the user, e.g. by using Ctrl-C in the terminal</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In both cases, PerfTest tries to exit as cleanly as possible, in a reasonable amount of time.
Nevertheless, when PerfTest AMQP connections are throttled by the broker, because they&#8217;re
publishing too fast or because broker <a href="https://www.rabbitmq.com/alarms.html">alarms</a>
have kicked in, it can take time to close them (several seconds or more for one connection).</p>
</div>
<div class="paragraph">
<p>If closing connections in the gentle way takes too long (5 seconds by default), PerfTest
will move on to the most important resources to free and terminates. This can result
in <code>client unexpectedly closed TCP connection</code> messages in the broker logs. Note this
means the AMQP connection hasn&#8217;t been closed with the right sequence of AMQP frames,
but the socket has been closed properly. There&#8217;s no resource leakage here.</p>
</div>
<div class="paragraph">
<p>The connection closing timeout can be set up with the <code>--shutdown-timeout</code> argument (or <code>-st</code>).
The default timeout can be increased to let more time to close connections, e.g. the
command below uses a shutdown timeout of 20 seconds:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --shutdown-timeout 20</pre>
</div>
</div>
<div class="paragraph">
<p>The connection closing sequence can also be skipped by setting the timeout to 0 or any negative
value:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --shutdown-timeout -1</pre>
</div>
</div>
<div class="paragraph">
<p>With the previous command, PerfTest won&#8217;t even try to close AMQP connections, it will exit
as fast as possible, freeing only the most important resources. This is perfectly
acceptable when performing runs on a test environment.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="customising-queues"><a class="anchor" href="#customising-queues"></a>Customising queues</h2>
<div class="sectionbody">
<div class="paragraph">
<p>PerfTest can create queues using provided <a href="https://rabbitmq.com/queues.html#optional-arguments">queue arguments</a>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --queue-args x-max-length=10</pre>
</div>
</div>
<div class="paragraph">
<p>The previous command will create a <a href="https://www.rabbitmq.com/maxlength.html">queue with a length limit</a>
of 10. You can also provide several queue arguments by separating the
key/value pairs with commas:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --queue-args x-max-length=10,x-dead-letter-exchange=some.exchange.name</pre>
</div>
</div>
<div class="paragraph">
<p>Some commonly supported queue arguments are available thanks to dedicated flags:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>--max-length-bytes</code>: <a href="https://rabbitmq.com/maxlength.html">maximum size</a> of created queues</p>
</li>
<li>
<p><code>--leader-locator</code>: leader location strategy for <a href="https://www.rabbitmq.com/quorum-queues.html#leader-placement">quorum queues</a> and <a href="https://www.rabbitmq.com/streams.html#leader-election">streams</a>, supported values are <code>client-local</code> and <code>balanced</code></p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="quorum-queue-support"><a class="anchor" href="#quorum-queue-support"></a>Quorum Queue Support</h3>
<div class="paragraph">
<p>It is possible to use several arguments to create <a href="https://rabbitmq.com/quorum-queues.html">quorum queues</a>, but PerfTest provides a <code>--quorum-queue</code> flag to do that:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --quorum-queue --queue qq</pre>
</div>
</div>
<div class="paragraph">
<p><code>--quorum-queue</code> is a shortcut for <code>--flag persistent --queue-args x-queue-type=quorum --auto-delete false</code>.
Note a quorum queue cannot have a server-generated name, so the <code>--queue</code> argument must be used to specify the name of the queue(s).</p>
</div>
</div>
<div class="sect2">
<h3 id="stream-support"><a class="anchor" href="#stream-support"></a>Stream Support</h3>
<div class="paragraph">
<p>PerfTest provides flags and options to configure <a href="https://rabbitmq.com/streams.html">streams</a> and use them on top of the AMQP 0.9.1 protocol.
Use the <code>--stream-queue</code> flag to create streams instead of classic queues:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --stream-queue --queue sq</pre>
</div>
</div>
<div class="paragraph">
<p>Note a stream cannot have a server-generated name, so the <code>--queue</code> argument must be used to specify the name of the stream(s).</p>
</div>
<div class="paragraph">
<p><code>--stream-queue</code> automatically sets the <code>--qos</code> flag to 200.</p>
</div>
<div class="paragraph">
<p>The following stream-related flags are also available, the defaults applied by <code>--stream-queue</code> are mentioned in parentheses (if any):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>--max-length-bytes</code>: <a href="https://rabbitmq.com/streams.html#retention">maximum size</a> of created streams, use 0 for no limit (<code>20gb</code>)</p>
</li>
<li>
<p><code>--stream-max-segment-size-bytes</code>: <a href="https://rabbitmq.com/streams.html#retention">maximum size</a> of stream segments (<code>500mb</code>)</p>
</li>
<li>
<p><code>--max-age</code>: <a href="https://rabbitmq.com/streams.html#retention">maximum age</a> of stream segments using the <a href="https://en.wikipedia.org/wiki/ISO_8601#Durations">ISO 8601 duration format</a>, e.g. PT10M30S for 10 minutes 30 seconds, P5DT8H for 5 days 8 hours</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>See the <a href="#consuming-from-streams">stream consumer section</a> for details on how to consume from a stream.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
PerfTest uses the AMQP 0.9.1 protocol.
Use <a href="https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#the-performance-tool">Stream PerfTest</a> if you want to test <a href="https://rabbitmq.com/streams.html">RabbitMQ Streams</a> with the <a href="https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbitmq_stream/docs/PROTOCOL.adoc">stream protocol</a>.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="customising-messages"><a class="anchor" href="#customising-messages"></a>Customising messages</h2>
<div class="sectionbody">
<div class="paragraph">
<p>It is possible to customise messages that PerfTest publishes. This allows
getting as close as possible to the target traffic or to populate queues
with messages that real consumers will process.</p>
</div>
<div class="sect2">
<h3 id="message-properties"><a class="anchor" href="#message-properties"></a>Message Properties</h3>
<div class="paragraph">
<p>You can specify message properties with key/value pairs separated by commas:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --message-properties priority=5,timestamp=2007-12-03T10:15:30+01:00</pre>
</div>
</div>
<div class="paragraph">
<p>The supported property keys are: <code>contentType</code>, <code>contentEncoding</code>,
<code>deliveryMode</code>, <code>priority</code>, <code>correlationId</code>, <code>replyTo</code>, <code>expiration</code>, <code>messageId</code>,
<code>timestamp</code>, <code>type</code>, <code>userId</code>, <code>appId</code>, <code>clusterId</code>. If some provided
keys do not belong to the previous list, the pairs will be considered
as headers (arbitrary key/value pairs):</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --message-properties priority=10,header1=value1,header2=value2</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="message-payload-from-files"><a class="anchor" href="#message-payload-from-files"></a>Message Payload from Files</h3>
<div class="paragraph">
<p>You can mimic real messages by specifying their content and
content type. This can be useful when plugging real application
consumers downstream. The content can come from one or several files and
the content-type can be specified:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --consumers 0 \
  --body content1.json,content2.json --body-content-type application/json</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Make sure to also set <code>--body</code> in a consumer-only PerfTest instance if it consumes messages published with it.
This is to tell PerfTest how to extract the message timestamp to calculate latency.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="random-json-payload"><a class="anchor" href="#random-json-payload"></a>Random JSON Payload</h3>
<div class="paragraph">
<p>PerfTest can generate random JSON payload for messages. This is useful to
experiment with traffic that (almost) always changes. To generate random JSON
payloads, use the <code>--json-body</code> flag and the <code>--size</code> argument to specify
the size in bytes:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --json-body --size 16000</pre>
</div>
</div>
<div class="paragraph">
<p>Generate random values is costly, so PerfTest generates a pool of payloads upfront
and uses them randomly in published messages. This way the generation of payloads
does not impede publishing rate. There are 2 options to change the pre-generation of
random JSON payload:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>--body-count</code>: the size of the pool of payloads PerfTest will generate and use in
published messages. The default size is 100. Increase this value if you want more
randomness in published messages.</p>
</li>
<li>
<p><code>--body-field-count</code>: the size of the pool of random strings used for field names and
values in the JSON document. Before generating JSON payloads, PerfTest generates random
strings and will use them randomly for field names and values in the JSON documents.
The default value is 1,000. Increasing this value can be useful for "large"
payloads (a few hundreds of kilobytes or more), which can "exhaust" the pool of random strings
and then end up with duplicated field names. Duplicated field names are fine if
the random JSON payloads are used to simulate traffic, but can be problematic if real
consumers are plugged in and try to parse the JSON documents
(JSON parsers do not always tolerate duplicated fields).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The defaults for <code>--body-count</code> and <code>--body-field-count</code> are usually fine, but can be increased
for more randomness, at the cost of slower startup time and higher memory consumption.</p>
</div>
<div class="paragraph">
<p>Bear in mind that a large cache of generated payloads combined with a moderately large size
can easily take up a significant amount of memory. As an example, <code>--json-body --body-count 50000 --size 100000</code>
(50,000 payloads of 100 kB) will use about 5 GB of memory.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Make sure to also set <code>--json-body</code> in a consumer-only PerfTest instance if it consumes messages published with it.
This is to tell PerfTest how to extract the message timestamp to calculate latency.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="limiting-and-varying-publishing-rate"><a class="anchor" href="#limiting-and-varying-publishing-rate"></a>Limiting and varying publishing rate</h2>
<div class="sectionbody">
<div class="paragraph">
<p>By default, PerfTest publishes as fast as possible.
The publishing rate per producer can be limited with the <code>--rate</code> option (<code>-r</code>). E.g. to
publishing at most 100 messages per second for the whole run:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --rate 100</pre>
</div>
</div>
<div class="paragraph">
<p>The <code>--variable-rate</code> (<code>-vr</code>) option can be used several times to specify a publishing rate
for a duration, e.g.:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --variable-rate 100:60 --variable-rate 1000:10 --variable-rate 500:15</pre>
</div>
</div>
<div class="paragraph">
<p>The variable rate option uses the <code>[RATE]:[DURATION]</code> syntax, where <code>RATE</code> is in messages per second
and <code>DURATION</code> is in seconds. In the previous example, the publishing rate
will be 100 messages per second for 60 seconds, then 1000 messages per second
for 10 seconds, then 500 messages per second for 15 seconds, then back to 100 messages per second
for 60 seconds, and so on.</p>
</div>
<div class="paragraph">
<p>The <code>--variable-rate</code> option is useful to simulate steady rates and burst of messages for short periods.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="setting-and-varying-the-message-size"><a class="anchor" href="#setting-and-varying-the-message-size"></a>Setting and varying the message size</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The default size of the messages that PerfTest publishes is 12 bytes (PerfTest stores
some data in the message to calculate latency on the consumer side).</p>
</div>
<div class="paragraph">
<p>It is possible to make messages bigger with the <code>--size</code> (<code>-s</code>) option, e.g. to publish
4 kB messages:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --size 4000</pre>
</div>
</div>
<div class="paragraph">
<p>The <code>--variable-size</code> (<code>-vs</code>) option allows to specify different message sizes
for periods of time, e.g.:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --variable-size 1000:30 --variable-size 10000:20 --variable-size 5000:45</pre>
</div>
</div>
<div class="paragraph">
<p>The variable rate option uses the <code>[SIZE]:[DURATION]</code> syntax, where <code>SIZE</code> is in bytes
and <code>DURATION</code> is in seconds. In the previous example, the size of published messages
will be 1 kB for 30 seconds, then 10 kB for 20 seconds, then 5 kB for 45 seconds,
then back to 1 kB for 30 seconds, and so on.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="setting-and-varying-consumer-latency"><a class="anchor" href="#setting-and-varying-consumer-latency"></a>Setting and varying consumer latency</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You can simulate processing time per message with either a fixed or a variable latency value in microseconds.</p>
</div>
<div class="paragraph">
<p>The <code>--consumer-latency</code> (<code>-L</code>) option sets a fixed consumer latency in microseconds. In the example
below a 1 ms latency is set:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --consumer-latency 1000</pre>
</div>
</div>
<div class="paragraph">
<p>The <code>--variable-latency</code> (<code>-vl</code>) option sets a variable consumer latency. In the example below it is
set to 1 ms for 60 seconds then 1 second for 30 seconds:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --variable-latency 1000:60 --variable-latency 1000000:30</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="working-with-many-queues"><a class="anchor" href="#working-with-many-queues"></a>Working With Many Queues</h2>
<div class="sectionbody">
<div class="paragraph">
<p>PertTest supports balancing the publishing and the consumption
across a sequence of queues, e.g.:</p>
</div>
<div class="listingblock">
<div class="title">Using a sequence of queues</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 10 \
  --producers 100 --consumers 100</code></pre>
</div>
</div>
<div class="paragraph">
<p>The previous command would create the <code>perf-test-1</code>, <code>perf-test-2</code>, &#8230;&#8203;,
<code>perf-test-10</code> queues and spreads the producers and consumers across them.
This way each queue will have 10 consumers and 10 producers sending messages to it.</p>
</div>
<div class="paragraph">
<p>Load is balanced in a round-robin fashion:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 10 \
  --producers 15 --consumers 30</pre>
</div>
</div>
<div class="paragraph">
<p>With the previous command, queues from <code>perf-test-1</code> to <code>perf-test-5</code>
will have 2 producers, and queues from <code>perf-test-6</code> to <code>perf-test-10</code>
will have only 1 producer. Each queue will have 3 consumers.</p>
</div>
<div class="paragraph">
<p>Note the <code>--queue-pattern</code> value is a
<a href="https://docs.oracle.com/javase/7/docs/api/java/util/Formatter.html">Java printf-style format string</a>.
The queue index is the only argument passed in. The formatting is very close to C&#8217;s <code>printf</code>.
<code>--queue-pattern 'perf-test-%03d' --queue-pattern-from 1 --queue-pattern-to 500</code> would for
instance create queues from <code>perf-test-001</code> to <code>perf-test-500</code>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="simulating-high-loads"><a class="anchor" href="#simulating-high-loads"></a>Simulating High Loads</h2>
<div class="sectionbody">
<div class="paragraph">
<p>PerfTest can easily run hundreds of connections on a simple desktop machine.
Each producer and consumer use a Java thread and a TCP connection though,
so a PerfTest process can quickly run out of file descriptors, depending
on the OS settings. A simple solution is to use several PerfTest processes,
on the same machine or not. This is especially handy when combined
with the <a href="#working-with-many-queues">queue sequence</a> feature.</p>
</div>
<div class="paragraph">
<p>The following command line launches a first PerfTest process that
creates 500 queues (from <code>perf-test-1</code> to <code>perf-test-500</code>).
Each queue will have 3 consumers and 1 producer sending messages to it:</p>
</div>
<div class="listingblock">
<div class="title">Creating a first set of 500 queues</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 500 \
  --producers 500 --consumers 1500</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then the following command line launches a second PerfTest process
that creates 500 queues (from <code>perf-test-501</code> to <code>perf-test-1000</code>).
Each queue will have 3 consumers and 1 producer sending messages to it:</p>
</div>
<div class="listingblock">
<div class="title">Creating a second set of 500 queues</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
 --queue-pattern-from 501 --queue-pattern-to 1000 \
 --producers 500 --consumers 1500</code></pre>
</div>
</div>
<div class="paragraph">
<p>Those 2 processes will simulate 1000 producers and 3000 consumers spread
across 1000 queues.</p>
</div>
<div class="paragraph">
<p>A PerfTest process can exhaust its file descriptors limit and throw
<code>java.lang.OutOfMemoryError: unable to create new native thread</code>
exceptions. A first way to avoid this is to reduce the number of Java threads
PerfTest uses with the <code>--heartbeat-sender-threads</code> option:</p>
</div>
<div class="listingblock">
<div class="title">Using <code>--heartbeat-sender-threads</code> to reduce the number of threads</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 1000 \
  --producers 1000 --consumers 3000 --heartbeat-sender-threads 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>By default, each producer and consumer connection uses a dedicated thread
to send heartbeats to the broker, so this is 4000 threads for heartbeats
in the previous sample. Considering producers and consumers always communicate
with the broker by publishing messages or sending acknowledgments, connections
are never idle, so using 10 threads for heartbeats for the 4000 connections
should be enough. Don&#8217;t hesitate to experiment to come up with the appropriate
<code>--heartbeat-sender-threads</code> value for your use case.</p>
</div>
<div class="paragraph">
<p>Another way to avoid <code>java.lang.OutOfMemoryError: unable to create new native thread</code>
exceptions is to tune the number of file descriptors allowed per process
at the OS level, as some distributions use very low limits.
Here the recommendations are the same as for the broker, so you
can refer to our <a href="https://www.rabbitmq.com/networking.html#os-tuning">networking guide</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="workloads-with-a-large-number-of-clients"><a class="anchor" href="#workloads-with-a-large-number-of-clients"></a>Workloads With a Large Number of Clients</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A typical connected device workload (a.k.a "IoT workload") involves
many producers and consumers (dozens or hundreds of thousands)
that exchange messages at a low and mostly constant rate, usually a message every few seconds or minutes.
Simulating such workloads requires a different set of settings compared to
the workloads that have higher throughput and a small number of clients. With the appropriate set of flags,
PerfTest can simulate IoT workloads without requiring too many resources, especially threads.
Let&#8217;s explore these flags.</p>
</div>
<div class="paragraph">
<p>With an IoT workload, publishers usually don&#8217;t publish many messages per second,
but rather a message every fixed period of time. This can be achieved by using the <code>--publishing-interval</code>
flag instead of the <code>--rate</code> one. For example:</p>
</div>
<div class="listingblock">
<div class="title">Using <code>--publishing-interval</code> for low-throughput workloads</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --publishing-interval 5</code></pre>
</div>
</div>
<div class="paragraph">
<p>The command above makes the publisher publish a message every 5 seconds.
To simulate a group of consumers, use the <code>--queue-pattern</code> flag to simulate many consumers across
many queues:</p>
</div>
<div class="listingblock">
<div class="title">Simulating 2000 clients on 1000 queues</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 1000 \
  --producers 1000 --consumers 1000 \
  --heartbeat-sender-threads 10 \
  --publishing-interval 5</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="title">Mind the sampling interval with slow publishers!</div>
<div class="paragraph">
<p>The <code>--interval</code> option (<code>-i</code>) sets the sampling interval for statistics and defaults to 1 second.
Keeping this value with slow publishers (1 message per second or less with <code>--publishing-interval</code>) can cause dips for some metrics, as they may not get any value for a while.
Note this affects only metrics and not the way PerfTest or the broker behave.
To avoid the metrics dips, you can increase the value of the sampling interval – twice the value of the publishing interval is a reasonable rule of thumb – or use the <code>--producer-random-start-delay</code> option to ramp up the start of publishers (see below).</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To prevent publishers from publishing at roughly the same time and
distribute the rate more evenly, use
the <code>--producer-random-start-delay</code> option to add a random
delay before the first published message:</p>
</div>
<div class="listingblock">
<div class="title">Using <code>--producer-random-start-delay</code> to spread publishing in a random way</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 1000 \
  --producers 1000 --consumers 1000 \
  --heartbeat-sender-threads 10 \
  --publishing-interval 5 --producer-random-start-delay 120</code></pre>
</div>
</div>
<div class="paragraph">
<p>With the command above, each publisher will start with a random delay
between 1 and 120 seconds.</p>
</div>
<div class="paragraph">
<p>When using <code>--publishing-interval</code>, PerfTest will use one thread for 100 operations per second.
So 1,000 producers publishing at 1 message / second should keep 10 threads busy for
the publishing scheduling.
It is possible to set the number of threads used with the <code>--producer-scheduler-threads</code> options.
Set your own value if the default value is not appropriate for some reasons:</p>
</div>
<div class="listingblock">
<div class="title">Using <code>--producer-scheduler-threads</code> to set the number of publishing threads</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 1000 \
  --producers 1000 --consumers 1000 \
  --heartbeat-sender-threads 10 \
  --publishing-interval 60 --producer-random-start-delay 1800 \
  --producer-scheduler-threads 5</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the example above, 1000 publishers will publish every 60 seconds
with a random start-up delay between 1 second and 30 minutes (1800 seconds). They
will be scheduled by only 5 threads. Such delay
values are suitable for long running tests.</p>
</div>
<div class="paragraph">
<p>Another option can be useful when simulating many consumers with a moderate message rate:
<code>--consumers-thread-pools</code>. It allows to use a given number of thread pools for all the consumers,
instead of one thread pool for each consumer by default. In the previous example, each consumer
would use a 1-thread thread pool, which is overkill considering consumers processing
is fast and producers publish one message every second. We can set the number of thread pools
to use with <code>--consumers-thread-pools</code> and they will be shared by the consumers:</p>
</div>
<div class="listingblock">
<div class="title">Using <code>--consumers-thread-pools</code> to reduce the number of consumer threads</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 1000 \
  --producers 1000 --consumers 1000 \
  --heartbeat-sender-threads 10 \
  --publishing-interval 60 --producer-random-start-delay 1800 \
  --producer-scheduler-threads 10 \
  --consumers-thread-pools 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>The previous example uses only 10 thread pools for all consumers instead of 1000 by default.
These are 1-thread thread pools in this case, so this is 10 threads overall instead of 1000, another
huge resource saving to simulate more clients with a single PerfTest instance for large IoT workloads.</p>
</div>
<div class="paragraph">
<p>By default, PerfTest uses blocking network socket I/O to communicate with
the broker. This mode works fine for clients in many cases but the RabbitMQ Java client
also supports an <a href="https://www.rabbitmq.com/api-guide.html#java-nio">asynchronous I/O mode</a>,
where resources like threads can be easily tuned. The goal here is to use as few
resources as possible to simulate as much load as possible with a single PerfTest instance.
In the slow publisher example above, a handful of threads should be enough
to handle the I/O. That&#8217;s what the
<code>--nio-threads</code> flag is for:</p>
</div>
<div class="listingblock">
<div class="title">Reducing the number of IO threads by enabling the NIO mode with <code>--nio-threads</code></div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">java -jar perf-test.jar --queue-pattern 'perf-test-%d' \
  --queue-pattern-from 1 --queue-pattern-to 1000 \
  --producers 1000 --consumers 1000 \
  --heartbeat-sender-threads 10 \
  --publishing-interval 60 --producer-random-start-delay 1800 \
  --producer-scheduler-threads 10 \
  --nio-threads 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>This way PerfTest will use  12 threads for I/O over all the connections.
With the default blocking I/O mode, each producer (or consumer)
uses a thread for the I/O loop, that is 2000 threads to simulate 1000 producers and
1000 consumers. Using NIO in PerfTest can dramatically reduce the resources used
to simulate workloads with a large number of connections with appropriate tuning.</p>
</div>
<div class="paragraph">
<p>Note that in NIO mode the number of threads used can increase temporarily when connections close
unexpectedly and connection recovery kicks in. This is due to the NIO mode dispatching
connection closing to non-I/O threads to avoid deadlocks. Connection recovery can be disabled
with the <code>--disable-connection-recovery</code> flag.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="running-producers-and-consumers-on-different-machines"><a class="anchor" href="#running-producers-and-consumers-on-different-machines"></a>Running Producers and Consumers on Different Machines</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you run producers and consumers on different machines or even
in different processes, and you want PerfTest to calculate latency,
you need to use the <code>--use-millis</code> flag. E.g. for sending messages
from one host:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --producers 1 --consumers 0 \
  --predeclared --routing-key rk --queue q --use-millis</pre>
</div>
</div>
<div class="paragraph">
<p>And for consuming messages from another host:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --producers 0 --consumers 1 \
  --predeclared --routing-key rk --queue q --use-millis</pre>
</div>
</div>
<div class="paragraph">
<p>Note that as soon as you use <code>--use-millis</code>, latency is calculated in
milliseconds instead of microseconds. Note also the different machines should have
their clock synchronised, e.g. by NTP.
If you don&#8217;t run producers and consumers on different machines or if you don&#8217;t
want PerfTest to calculate latency, you don&#8217;t need the <code>--use-millis</code> flag.</p>
</div>
<div class="paragraph">
<p>Why does one need to care about the <code>--use-millis</code> flag? PerfTest uses
by default <code>System.nanoTime()</code> in messages to calculate latency
between producers and senders. <code>System.nanoTime()</code> provides nanosecond precision
but must be used only in the same Java process. So PerfTest can fall back to <code>System.currentTimeMillis()</code>,
which provides only milliseconds precision, but is reliable between different machines
as long as their clocks are synchronised.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="asynchronous-consumers-vs-synchronous-consumers"><a class="anchor" href="#asynchronous-consumers-vs-synchronous-consumers"></a>Asynchronous Consumers vs Synchronous Consumers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Consumers are asynchronous by default in PerfTest. This means they are registered with the AMQP <code>basic.consume</code>
method and the broker pushes messages to them. This is the optimal way to consume messages. PerfTest
also provides the <code>--polling</code> and <code>--polling-interval</code> options to consume messages by polling the broker
with the AMQP <code>basic.get</code> method. These options are available to evaluate the performance and the effects
of <code>basic.get</code>, but real applications should avoid using <code>basic.get</code> as much as possible because
it has several drawbacks compared to asynchronous consumers: it needs a network round trip for each message,
it typically keeps a thread busy for polling in the application, and it intrinsically increases latency.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="consuming-from-streams"><a class="anchor" href="#consuming-from-streams"></a>Consuming From Streams</h2>
<div class="sectionbody">
<div class="paragraph">
<p>RabbitMQ streams model an append-only log with non-destructive consumer semantics.
PerfTest uses the AMQP 0.9.1 protocol to interact with streams.
The <a href="#stream-support">queue customisation section</a> covers how to declare streams with PerfTest.</p>
</div>
<div class="paragraph">
<p>Acknowledgments and <a href="https://www.rabbitmq.com/confirms.html#channel-qos-prefetch">consumer prefetch</a> are mandatory when consuming from a stream, so the <code>--qos</code> flag must be specified.
The following example sets up a consume-only run from the already-existing <code>invoices</code> stream with consumer prefetch so to 200:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 0 -y 1 --predeclared \
   --queue invoices --qos 200</pre>
</div>
</div>
<div class="paragraph">
<p>Note a consumer attaches to the end of a stream by default (<code>next</code> <a href="https://rabbitmq.com/streams.html#consuming">offset</a>).
This means the consumer does not get any messages if no publishers add messages to the stream at that time.
Use the <code>--stream-consumer-offset</code> flag to change the default, for example <code>first</code> to start at the beginning of the stream:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -x 0 -y 1 --predeclared \
   --queue invoices --qos 200 --stream-consumer-offset first</pre>
</div>
</div>
<div class="paragraph">
<p>Valid values for <code>--stream-consumer-offset</code> are <code>first</code>, <code>last</code>, <code>next</code>, an unsigned long for the absolute offset in the stream, or an <a href="https://en.wikipedia.org/wiki/ISO_8601#Combined_date_and_time_representations">ISO 8601 formatted timestamp</a> (eg. <code>2022-06-03T07:45:54Z</code>) to attach to a point in time.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
PerfTest uses the AMQP 0.9.1 protocol.
Use <a href="https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#the-performance-tool">Stream PerfTest</a> if you want to test <a href="https://rabbitmq.com/streams.html">RabbitMQ Streams</a> with the <a href="https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbitmq_stream/docs/PROTOCOL.adoc">stream protocol</a>.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="instance-synchronization"><a class="anchor" href="#instance-synchronization"></a>Synchronizing Several Instances</h2>
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
This feature is available only on Java 11 or more.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>PerfTest instances can synchronize to start at the same time.
This can prove useful when you apply different workloads and want to compare them on the same monitoring graphics.
The <code>--id</code> flag identifies the group of instances that need to synchronize and the <code>--expected-instances</code> flag sets the size of the group.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s take a somewhat artificial example to keep flags as simple as possible and compare the behavior of an auto-delete queue to a quorum queue.
We start the first PerfTest instance:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --id auto-delete-vs-qq --expected-instances 2</pre>
</div>
</div>
<div class="paragraph">
<p>The instance will wait until the second one is ready:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --id auto-delete-vs-qq --expected-instances 2 \
  --quorum-queue --queue qq</pre>
</div>
</div>
<div class="paragraph">
<p>Both instances <em>must</em> share the same <code>--id</code> if they want to communicate to synchronize.
Note synchronized instances creates connections before starting the synchronization process.
They are then ready to start their respective workload (publishing and/or consuming) when all the expected instances have joined the group.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Instance synchronization is compatible with <a href="https://rabbitmq.github.io/rabbitmq-stream-java-client/snapshot/htmlsingle/#performant-tool-instance-synchronization">StreamPerfTest</a>, the performance tool for RabbitMQ streams: instances of both tools can synchronize with each other.
The 2 tools use the same flags for this feature.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The default synchronization timeout is 10 minutes.
This can be changed with the <code>--instance-sync-timeout</code> flag, using a value in seconds.</p>
</div>
<div class="paragraph">
<p>PerfTest instance synchronization requires <a href="https://en.wikipedia.org/wiki/IP_multicast">IP multicast</a> to be available.
IP multicast is not necessary when PerfTest runs on Kubernetes pods.
In this case, PerfTest asks Kubernetes for a list of pod IPs.
The PerfTest instances are expected to run in the same namespace, and the namespace must be available in the <code>MY_POD_NAMESPACE</code> environment variable or provided with the <code>--instance-sync-namespace</code> flag.
As soon as the namespace information is available, PerfTest will prefer listing pod IPs over using IP multicast.
Here is an example of using instance synchronization on Kubernetes by providing the namespace explicitly:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --id workload-1 --expected-instances 2 \
  --instance-sync-namespace qa</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
PerfTest needs permission to ask Kubernetes for a list of pod IPs.
This is done by creating various policies e.g. with YAML.
See the <a href="https://github.com/jgroups-extras/jgroups-kubernetes">Kubernetes discovery protocol for JGroups page</a> for more information.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="tls-support"><a class="anchor" href="#tls-support"></a>TLS Support</h2>
<div class="sectionbody">
<div class="paragraph">
<p>PerfTest can use TLS to connect to a node that is <a href="https://www.rabbitmq.com/ssl.html">configured to accept TLS connections</a>.
To enable TLS, simply specify a URI that uses the <code>amqps</code> schema:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar -h amqps://localhost:5671</pre>
</div>
</div>
<div class="paragraph">
<p>By default, PerfTest automatically trusts the server and doesn&#8217;t present any client certificate (a warning
shows up in the console).
In many benchmarking or load testing scenarios this may be sufficient.
If peer verification is necessary, it is possible to use the <a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/jsse/JSSERefGuide.html#InstallationAndCustomization">appropriate
JVM properties</a> on the command line to override the default <code>SSLContext</code>.
For example, to trust a given server:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -Djavax.net.ssl.trustStore=/path/to/server_key.p12 \
     -Djavax.net.ssl.trustStorePassword=bunnies \
     -Djavax.net.ssl.trustStoreType=PKCS12 \
     -jar perf-test.jar -h amqps://localhost:5671</pre>
</div>
</div>
<div class="paragraph">
<p>The previous snippet defines appropriate system properties to locate the trust store to use.
Please refer to the <a href="https://www.rabbitmq.com/ssl.html">TLS guide</a> to learn about how to set up RabbitMQ with TLS.
A convenient way to generate a CA and some self-signed certificate/key pairs for development and QA environments is with <a href="https://github.com/rabbitmq/tls-gen"><code>tls-gen</code></a>.
<code>tls-gen</code> basic profile is a good starting point.
Once the TLS artifacts generated by <code>tls-gen</code>, you have to generate a trust store file with the server or CA certificate in it.
<code>keytool</code> can do this:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>keytool -import -file server_certificate.pem \
  -keystore server_certificate.p12 -storepass bunnies -storetype PKCS12 \
  -noprompt</pre>
</div>
</div>
<div class="paragraph">
<p>And here is how to run PerfTest with a certificate/key pair generated by <code>tls-gen</code> basic profile and the trust store:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -Djavax.net.ssl.trustStore=/path/to/server_certificate.p12 \
     -Djavax.net.ssl.trustStorePassword=bunnies \
     -Djavax.net.ssl.trustStoreType=PKCS12 \
     -Djavax.net.ssl.keyStore=/path/to/client_key.p12 \
     -Djavax.net.ssl.keyStorePassword=bunnies \
     -Djavax.net.ssl.keyStoreType=PKCS12 \
     -jar perf-test.jar -h amqps://localhost:5671</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="oauth2-authenticationauthorization"><a class="anchor" href="#oauth2-authenticationauthorization"></a>OAuth2 authentication/authorization</h2>
<div class="sectionbody">
<div class="paragraph">
<p>It&#8217;s possible to connect to a RabbitMQ instance configured to use
<a href="https://www.rabbitmq.com/oauth2.html">OAuth 2.0 Authentication
Backend</a>. In this case it is not necessary to provide a username and a
password in the AMQP URI: a token endpoint URI, client id and
client secret should be provided as separate command line options instead.
All 3 should be specified at once.</p>
</div>
<div class="paragraph">
<p>Here is an example:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --uri amqps://some-uri-without-user-and-password:5671 \
  --oauth2-token-endpoint https://example.com/api/auth/token \
  --oauth2-client-id 12345 \
  --oauth2-client-secret qwerty \
  --oauth2-grant-type client_credentials \
  --oauth2-parameters orgId=1212 \
  --oauth2-parameters subject_token_type=urn:ietf:params:oauth:token-type:access_token</pre>
</div>
</div>
<div class="paragraph">
<p><code>--oauth2-grant-type</code> is optional and defaults to <code>client_credential</code>.</p>
</div>
<div class="paragraph">
<p>Any number of optional parameters can be passed to the token endpoint via
the <code>--oauth2-parameters</code> option.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="using-environment-variables-as-options"><a class="anchor" href="#using-environment-variables-as-options"></a>Using Environment Variables as Options</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Environment variables can sometimes be easier to work with than command line options, for example
when using a manifest file to configure PerfTest (with Docker Compose or Kubernetes), especially when
the number of options used grows.</p>
</div>
<div class="paragraph">
<p>PerfTest will automatically use environment variables that match the snake case version of the long version of its options
(e.g. PerfTest will automatically pick up the value of the <code>CONFIRM_TIMEOUT</code> environment variable
for the <code>--confirm-timeout</code> option, but only if the environment variable is defined).</p>
</div>
<div class="paragraph">
<p>You can list the environment variables that PerfTest will pick up with the following command:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar --env</pre>
</div>
</div>
<div class="paragraph">
<p>Note that some options can be used several times to define several values, e.g.:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>java -jar perf-test.jar \
  --variable-rate 100:60 --variable-rate 1000:10 --variable-rate 500:15</pre>
</div>
</div>
<div class="paragraph">
<p>Declaring an environment variable several times just overrides the previous value, so to
define several values for an environment variable, just separate the values with a comma:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>VARIABLE_RATE="100:60,1000:10,500:15"</pre>
</div>
</div>
<div class="paragraph">
<p>To avoid collisions with environment variables that already exist, it is possible to specify
a prefix for the environment variables that PerfTest will look up. This prefix is defined
with the <code>RABBITMQ_PERF_TEST_ENV_PREFIX</code> environment variable, e.g.:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>RABBITMQ_PERF_TEST_ENV_PREFIX="PERF_TEST_"</pre>
</div>
</div>
<div class="paragraph">
<p>With <code>RABBITMQ_PERF_TEST_ENV_PREFIX="PERF_TEST_"</code> defined, PerfTest will for example look for
the <code>PERF_TEST_CONFIRM_TIMEOUT</code> environment variable, not only <code>CONFIRM_TIMEOUT</code>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="console-output-format"><a class="anchor" href="#console-output-format"></a>Console Output Format</h2>
<div class="sectionbody">
<div class="paragraph">
<p>PerfTest default console output format is explicit as each line contains a label for each value:</p>
</div>
<div class="listingblock">
<div class="title">The <code>default</code> output format</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">id: test-101517-299, time 1.000 s, sent: 188898 msg/s, received: 85309 msg/s, min/median/75th/95th/99th consumer latency: 24/234/364/462/474 ms
id: test-101517-299, time 2.000 s, sent: 101939 msg/s, received: 117152 msg/s, min/median/75th/95th/99th consumer latency: 483/759/830/896/907 ms
id: test-101517-299, time 3.000 s, sent: 137450 msg/s, received: 118324 msg/s, min/median/75th/95th/99th consumer latency: 691/816/854/893/909 ms</code></pre>
</div>
</div>
<div class="paragraph">
<p>Advanced users who prefer a more compact format can use the <code>--metrics-format compact</code> option (<code>-mf compact</code> for short).
The output looks like the following then:</p>
</div>
<div class="listingblock">
<div class="title">The <code>compact</code> output format</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">time               sent     received       consumer latency
1.000s     173920 msg/s  84405 msg/s    1/25/189/312/331 ms
2.000s     133044 msg/s 117703 msg/s 329/728/814/887/897 ms
3.000s     103736 msg/s 117134 msg/s 705/804/846/892/920 ms</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="monitoring"><a class="anchor" href="#monitoring"></a>Monitoring</h2>
<div class="sectionbody">
<div class="paragraph">
<p>PerfTest can gather metrics and make them available to various monitoring
systems. Metrics include messaging-centric metrics (message latency,
number of connections and channels, number of published messages, etc) as well
as OS process and JVM metrics (memory, CPU usage, garbage collection, JVM heap, etc).</p>
</div>
<div class="paragraph">
<p>Here is how to list the available metrics options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>java -jar perf-test.jar --metrics-help</pre>
</div>
</div>
<div class="paragraph">
<p>This command displays the available flags to enable the various metrics PerfTest
can gather, as well as options to configure the exposure to the monitoring systems
PerfTest supports.</p>
</div>
<div class="sect2">
<h3 id="supported-metrics"><a class="anchor" href="#supported-metrics"></a>Supported Metrics</h3>
<div class="paragraph">
<p>Here are the metrics PerfTest can gather:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>default metrics: number of published, returned, confirmed, nacked, and consumed messages, message
latency, publisher confirm latency. Message latency is a major concern in many types of workload, it can be easily monitored here.
<a href="https://www.rabbitmq.com/confirms.html#publisher-confirms">Publisher confirm</a>
latency reflects the time a message can be considered unsafe. It is
calculated as soon as the <code>--confirm</code>/<code>-c</code> option is used.
Default metrics are available as long as PerfTest support for a monitoring system
is enabled.</p>
</li>
<li>
<p>client metrics: these are the <a href="https://www.rabbitmq.com/api-guide.html#metrics">Java Client metrics</a>.
Enabling these metrics shouldn&#8217;t bring much compared to the default PerfTest metrics,
except to see how PerfTest behaves with regards to number of open connections
and channels for instance. Client metrics are enabled with the <code>-mc</code> or <code>--metrics-client</code> flag.</p>
</li>
<li>
<p>JVM memory metrics: these metrics report memory usage of the JVM, e.g. current heap size, etc.
They can be useful to have a better understanding of the client behavior, e.g. heap memory fluctuation
could be due to frequent garbage collection that could explain high latency numbers. These metrics
are enabled with the <code>-mjm</code> or <code>--metrics-jvm-memory</code> flag.</p>
</li>
<li>
<p>JVM thread metrics: these metrics report the number of JVM threads used in the PerfTest process,
as well as their state. This can be useful to optimize the usage of PerfTest to simulate
<a href="#workloads-with-a-large-number-of-clients">high loads with fewer resources</a>.
These metrics are enabled with the <code>-mjt</code> or <code>--metrics-jvm-thread</code> flag.</p>
</li>
<li>
<p>JVM GC metrics: these metrics reports garbage collection activity. They can vary depending
on the JVM used, its version, and the GC settings. They can be useful to correlate the GC
activity with PerfTest behavior, e.g. abnormal low throughput because of very frequent
garbage collection. These metrics are enabled with the <code>-mjgc</code> or <code>--metrics-jvm-gc</code> flag.</p>
</li>
<li>
<p>JVM class loader metrics: the number of loaded and unloaded classes. These metrics
are enabled with the <code>-mcl</code> or <code>--metrics-class-loader</code> flag.</p>
</li>
<li>
<p>Processor metrics: there metrics report CPU activity as gathered by the JVM.
They can be enabled with the <code>-mjp</code> or <code>--metrics-processor</code> flag.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="tags"><a class="anchor" href="#tags"></a>Tags</h3>
<div class="paragraph">
<p>One can specify metrics tags with the <code>-mt</code> or <code>--metrics-tags</code> options, e.g.
<code>--metrics-tags env=performance,datacenter=eu</code> to tell monitoring systems that those
metrics are from the <code>performance</code> environment located in the <code>eu</code> data center.
Monitoring systems that support dimensions can then make it easier to
navigate across metrics (group by, drill down). See <a href="https://micrometer.io">Micrometer</a> documentation
for more information about tags and dimensions.</p>
</div>
</div>
<div class="sect2">
<h3 id="supported-monitoring-systems"><a class="anchor" href="#supported-monitoring-systems"></a>Supported Monitoring Systems</h3>
<div class="paragraph">
<p>PerfTest builds on top <a href="https://micrometer.io">Micrometer</a> to report gathered metrics to various monitoring systems.
Nevertheless, not all systems supported by Micrometer are actually supported by PerfTest.
PerfTest currently supports <a href="https://www.datadoghq.com/">Datadog</a>, <a href="https://en.wikipedia.org/wiki/Java_Management_Extensions">JMX</a>,
and <a href="https://prometheus.io/">Prometheus</a>.
Don&#8217;t hesitate to
<a href="https://github.com/rabbitmq/rabbitmq-perf-test/issues">request support for other monitoring systems</a>.</p>
</div>
<div class="sect3">
<h4 id="datadog"><a class="anchor" href="#datadog"></a>Datadog</h4>
<div class="paragraph">
<p>The API key is the only required option to send metrics to Datadog:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>java -jar perf-test.jar --metrics-datadog-api-key YOUR_API_KEY</code></pre>
</div>
</div>
<div class="paragraph">
<p>Another useful option is the step size or reporting frequency. The default value is
10 seconds.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>java -jar perf-test.jar --metrics-datadog-api-key YOUR_API_KEY \
    --metrics-datadog-step-size 20</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="jmx"><a class="anchor" href="#jmx"></a>JMX</h4>
<div class="paragraph">
<p>JMX support provides a simple way to view metrics locally. Use the <code>--metrics-jmx</code> flag to
export metrics to JMX:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>java -jar perf-test.jar --metrics-jmx</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="prometheus"><a class="anchor" href="#prometheus"></a>Prometheus</h4>
<div class="paragraph">
<p>Use the <code>-mpr</code> or <code>--metrics-prometheus</code> flag to enable metrics reporting to Prometheus:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>java -jar perf-test.jar --metrics-prometheus</code></pre>
</div>
</div>
<div class="paragraph">
<p>Prometheus expects to scrape or poll individual app instances for metrics, so PerfTest starts up
a web server listening on port 8080 and exposes metrics on the <code>/metrics</code> endpoint. These defaults
can be changed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>java -jar perf-test.jar --metrics-prometheus \
    --metrics-prometheus-port 8090 --metrics-prometheus-endpoint perf-test-metrics</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="expected-and-exposed-metrics"><a class="anchor" href="#expected-and-exposed-metrics"></a>Expected and Exposed Metrics</h3>
<div class="paragraph">
<p>PerfTest automatically exposes 2 <code>expected_published</code> and <code>expected_consumed</code> metrics that represent the theoretical published and consumed rates, respectively.
PertTest calculates the values and exposes the metrics as soon as rate instructions are provided (e.g. with <code>--rate</code> or <code>--consumer-rate</code>).</p>
</div>
<div class="paragraph">
<p>These expected metrics aim at helping external monitoring tools to trigger alerts if the actual rates are different from the expected rates.
PerfTest does its best to calculate and update the expected rates, but it may be wrong or just cannot figure out the correct values.
It is then possible to override the metrics values thanks to the <code>--exposed-metrics</code> option (<code>-em</code> for short):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>java -jar perf-test.jar --metrics-prometheus \
    --exposed-metrics expected_published=50000,expected_consumed=50000</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note PerfTest adds the metrics prefix to the provided name automatically (<code>perftest_</code> by default).</p>
</div>
<div class="paragraph">
<p>It is also possible to expose any metrics, e.g. setting an expected value for the publisher confirm latency so the external monitoring system could trigger an alert if the actual latency is higher:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>java -jar perf-test.jar --metrics-prometheus --rate 1000 \
    --exposed-metrics expected_confirm_latency=0.1</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 2.24.0-SNAPSHOT<br>
Last updated 2025-02-21 14:02:41 UTC
</div>
</div>
</body>
</html>